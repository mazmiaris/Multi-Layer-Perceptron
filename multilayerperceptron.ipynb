{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Backpropagation Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Layer Perceptron digunakan unntuk memecahkan masalah klasifikasi. Namun, tentu saja satu garis linear saja tidak cukup, maka dari itu dibutuhkan lebih dari satu garis linear untuk memecahkan masalah tersebut. Dibutuhkan lebih dari satu garis linear disebabkan karena adanya kelas target lebih dari 2, dan misalkan tersebar berdasarkan visualisasi, tentu saja tidak bisa digunakan hanya satu garis saja. Maka digunakan Multi Layer Perceptron. Perbedaan Multi layer Perceptron dengan Single Layer Perceptron ialah, pada MLP terdapat layer tambahan, yakni hidden layer, yang mana menjadi input untuk outputnya nanti. Untuk validasi, kita menggunakan datasplit, dengan data train sebanyak 80% dan data test sebanyak 20%. Multi Layer Perceptron menggunakan dua buah algoritma yang digunakan, pertama algoritma feedforward dan backpropagation. Feedforward langkahnya ialah: Menginisialisasi weight, bias,dll. Kemudian mengalikan input dengan weight kemudian ditambah bias agar mendapatkan input untuk hidden layer, lalu kemudian dimasukkan ke fungsi aktivasi.\n",
    "\n",
    "Untuk backpropagate sendiri, dia menghitung dari nilai error, berarti dari perbedaan output dengan target.kemudian menghitung slope/gradient, kemudian menghitung delta output layer, kemudian baru mengupdate weight di input dan output layer, dan mengupdate bias di output dan input. Di sini kita menggunakan dua alfa, yakni 0.1 dan 0.8. Untuk arsitektur MLPnya sendiri menggunakan tiga layer, yang mana 1 nya ialah hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d51c5fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from csv import reader\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset\n",
    "\n",
    "\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column]=float(row[column].strip())\n",
    "        \n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "def activate(row, theta):\n",
    "    result=theta[0]\n",
    "    for i in range (len(row)-1):\n",
    "        result+=theta[i+1]*row[i]\n",
    "        activation=1/(1+np.exp(-result))\n",
    "    return activation\n",
    "\n",
    "def accuracy_matriks(actual, predicted):\n",
    "    correct=0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct+=1\n",
    "    return correct/float(len(actual))*100.0\n",
    "\n",
    "#prediction\n",
    "def predict(row, theta):\n",
    "    result=theta[0]\n",
    "    for i in range (len(row)-1):\n",
    "        result+=theta[i+1]*row[i]\n",
    "        activation=1/(1+np.exp(-result))\n",
    "    return 1.0 if activation>0.5 else 0.0 \n",
    "\n",
    "#update weight\n",
    "\n",
    "\n",
    "def activate(row, theta):\n",
    "    result=theta[0]\n",
    "    for i in range (len(row)-1):\n",
    "        result+=theta[i+1]*row[i]\n",
    "        activation=1/(1+np.exp(-result))\n",
    "    return activation\n",
    "\n",
    "def sigmoid (x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#Derivative of Sigmoid Function\n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "iris1 = load_csv('irisnew2.csv')\n",
    "\n",
    "for i in range(len(iris1[0])-1):\n",
    "    str_column_to_float(iris1, i)\n",
    "    \n",
    "str_column_to_int(iris1, len(iris1[0])-1)\n",
    "\n",
    "\n",
    "alfa=0.1\n",
    "n_folds=5\n",
    "n_epoch=300\n",
    "\n",
    "theta=[0.5, 0.5, 0.5, 0.5]\n",
    "thetaout=[0.5,0.5,0.5,0.5]\n",
    "dtheta=[0.0, 0.0, 0.0, 0.0]\n",
    "biash=0.5\n",
    "biasout=0.5\n",
    "hidden_layer_input1=0\n",
    "output_layer_input1=0\n",
    "epoch2=list()\n",
    "errorli=list()\n",
    "epnum=0\n",
    "for epoch in range(n_epoch):  \n",
    "    epoch2.append(epnum) \n",
    "    for row in iris1:\n",
    "        for i in range(len(row)-1):\n",
    "            hidden_layer_input1=hidden_layer_input1+theta[i]*row[i]\n",
    "        hidden_layer_input=hidden_layer_input1+biash\n",
    "        hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "        for i in range(len(row)-1):\n",
    "            output_layer_input1=output_layer_input1+thetaout[i]*row[i]\n",
    "        output_layer_input= output_layer_input1+ biasout\n",
    "        output = sigmoid(output_layer_input)\n",
    "        \n",
    "        #Backpropagation\n",
    "        E = row[-1]-output\n",
    "        slope_output_layer = derivatives_sigmoid(output)\n",
    "        slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "        d_output = E * slope_output_layer\n",
    "        Error_at_hidden_layer=d_output*thetaout[0]+d_output*thetaout[1]+d_output*thetaout[2]+d_output*thetaout[3]\n",
    "        d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "        for i in range(len(row)-1):\n",
    "            thetaout[i] = thetaout[i]+hiddenlayer_activations*d_output *lr\n",
    "        biasout = biasout+ d_output *lr\n",
    "        for i in range(len(row)-1):\n",
    "            theta[i] = theta[i]+ row[i]*d_hiddenlayer *lr\n",
    "        bh =bh+d_hiddenlayer *lr\n",
    "    errorli.append(E)\n",
    "    epnum=epnum+1\n",
    "    \n",
    "plt.plot(epoch2, errorli, color='green')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
